# üîä ESC-50: Danger vs Safe Classification using PANNs (Cnn14)

## 1. M·ª•c ti√™u

Ph√¢n lo·∫°i √¢m thanh th√†nh 2 l·ªõp:

* **Danger** (Nguy hi·ªÉm)
* **Safe** (An to√†n)

S·ª≠ d·ª•ng dataset **ESC-50** (d·ªØ li·ªáu √¢m thanh ƒëa d·∫°ng, c√≥ g√°n nh√£n s·∫µn) k·∫øt h·ª£p v·ªõi pretrained model **PANNs ‚Äì Cnn14** ƒë·ªÉ tr√≠ch xu·∫•t embedding ƒë·∫∑c tr∆∞ng, sau ƒë√≥ hu·∫•n luy·ªán m√¥ h√¨nh ph√¢n lo·∫°i nh·ªã ph√¢n (binary classification).

---

## 2. Chu·∫©n b·ªã d·ªØ li·ªáu

1. **T√°ch d·ªØ li·ªáu**:

   * Vi·∫øt script `filterAudioToDangerousAndSafe.py` ƒë·ªÉ l·ªçc t·ª´ ESC-50 ‚Üí 2 th∆∞ m·ª•c:

     * `dataset/Danger`
     * `dataset/Safe`
   * G√°n nh√£n:

     * `Safe`: 0
     * `Danger`: 1
	
![image](https://github.com/user-attachments/assets/7393f533-945a-40d2-b368-fd1664880542)

2. **Tr√≠ch xu·∫•t embedding**:

   * Vi·∫øt script `extractEmbeddingCnn14.py` d√πng Cnn14 t·ª´ PANNs ƒë·ªÉ tr√≠ch xu·∫•t embedding cho m·ªói audio.
   * C·∫ßn ch·ªânh s·ª≠a class `Cnn14` trong `models.py` ƒë·ªÉ **tr·∫£ v·ªÅ embedding** thay v√¨ logits.

   ```python
   def forward(self, input, mixup_lambda=None):
       ...
       embedding = self.fc1_dropout(embedding)
       embedding = self.fc1(embedding)
       return {
           'clipwise_output': x,
           'embedding': embedding
       }
   ```

3. **Output**: File `audio_embeddings.csv` ch·ª©a c√°c embedding v√† nh√£n t∆∞∆°ng ·ª©ng.

---

## 3. Hu·∫•n luy·ªán m√¥ h√¨nh

B·∫Øt ƒë·∫ßu v·ªõi m√¥ h√¨nh ƒë∆°n gi·∫£n ƒë·ªÉ ƒë√°nh gi√° hi·ªáu qu·∫£ embedding:

### ‚úÖ ∆Øu ti√™n th·ª≠ tr∆∞·ªõc: **Random Forest**

* Kh√¥ng c·∫ßn chu·∫©n h√≥a d·ªØ li·ªáu
* Nhanh, √≠t c·∫ßn tinh ch·ªânh
* D·ªÖ di·ªÖn gi·∫£i

### üöÄ Ti·∫øn tr√¨nh:

1. Vi·∫øt script `train_rf_model.py`
2. Hu·∫•n luy·ªán m√¥ h√¨nh tr√™n `audio_embeddings.csv`
3. L∆∞u model: `rf_model.joblib`
4. ƒê√°nh gi√° v·ªõi **confusion matrix**:

![image](https://github.com/user-attachments/assets/00e828f0-9ec9-4a38-94a2-752f1540945f)


---

## 4. Nh·∫≠n x√©t

* **V·∫•n ƒë·ªÅ nghi√™m tr·ªçng**: M√¥ h√¨nh d·ª± ƒëo√°n to√†n b·ªô √¢m thanh l√† **Safe**:

  * TP Danger = 0, FP Safe = 40 ‚Üí M√¥ h√¨nh kh√¥ng h·ªçc ƒë∆∞·ª£c ƒë·∫∑c tr∆∞ng l·ªõp "Danger"

### üìâ Nguy√™n nh√¢n kh√¥ng ph·∫£i do m·∫•t c√¢n b·∫±ng nh√£n:

```python
import pandas as pd
df = pd.read_csv("audio_embeddings.csv")
print(df['label'].value_counts())
# Output:
# 0    200
# 1    160
```

T·ª∑ l·ªá l·ªõp v·∫´n t∆∞∆°ng ƒë·ªëi c√¢n b·∫±ng ‚Üí L·ªói ƒë·∫øn t·ª´ vi·ªác:

* M√¥ h√¨nh kh√¥ng h·ªçc ƒë∆∞·ª£c ƒë·∫∑c tr∆∞ng nguy hi·ªÉm t·ª´ embedding.

---

## 5. H∆∞·ªõng c·∫£i ti·∫øn

* **S·ª≠ d·ª•ng m√¥ h√¨nh nh·∫°y h∆°n v·ªõi embedding ƒë·∫∑c tr∆∞ng**:

  * Logistic Regression (LogReg)
  * Multi-layer Perceptron (MLP)
* **K·∫øt h·ª£p th√™m**:

  * `StandardScaler` ƒë·ªÉ chu·∫©n h√≥a
  * `class_weight='balanced'` ƒë·ªÉ tƒÉng tr·ªçng s·ªë l·ªõp "Danger"

---

## 6. Ghi ch√∫

* PANNs Cnn14 c·∫ßn ƒë∆∞·ª£c ch·ªânh s·ª≠a ƒë·ªÉ **xu·∫•t embedding**
* C√°c m√¥ h√¨nh nh∆∞ RF c√≥ th·ªÉ kh√¥ng ƒë·ªß m·∫°nh ƒë·ªÉ h·ªçc t·ªët tr√™n embedding ‚Äì n√™n th·ª≠ MLP ho·∫∑c fine-tuning n·∫øu c·∫ßn
### ‚ùå C√°c m√¥ h√¨nh kh√¥ng h·ªçc ƒë∆∞·ª£c l·ªõp Danger

* Logistic Regression d·ª± ƒëo√°n to√†n b·ªô th√†nh Safe (0)
* V√≠ d·ª• (Confusion Matrix ‚Äì Logistic Regression):

![image](https://github.com/user-attachments/assets/2d396061-1c6b-4baa-8755-a944d93e284d)


**Ph√¢n t√≠ch:**

* D·ªØ li·ªáu c√≥ 200 m·∫´u Safe vs 160 Danger ‚Üí KH√îNG m·∫•t c√¢n b·∫±ng ƒë√°ng k·ªÉ
* Nguy√™n nh√¢n th·ª±c t·∫ø: m·ªói sample c√≥ **nhi·ªÅu vector th·ªùi gian (multi-frame embedding)**, ch∆∞a g·ªôp v·ªÅ vector duy nh·∫•t

---

## 7. C·∫£i ti·∫øn: G·ªôp embedding b·∫±ng Pooling

### ‚úÖ V·∫•n ƒë·ªÅ:

C√°c vector embedding nh∆∞ `feat_0`, `feat_1`, ..., `feat_14` l√† **chu·ªói theo th·ªùi gian**, m·ªói b∆∞·ªõc c√≥ 2048 chi·ªÅu

‚Üí M√¥ h√¨nh nh∆∞ Logistic Regression y√™u c·∫ßu m·ªói sample l√† **m·ªôt vector c·ªë ƒë·ªãnh**

### ‚úÖ C√°ch x·ª≠ l√Ω:

S·ª≠ d·ª•ng **mean pooling**:

```python
merged = np.mean([feat_0, feat_1, ..., feat_14], axis=0)
```

* Vi·∫øt script `mergeFeat_x.py` ‚Üí xu·∫•t ra `merged_embeddings.csv`
* M·ªói d√≤ng l√† embedding duy nh·∫•t ·ª©ng v·ªõi 1 √¢m thanh (k√≠ch th∆∞·ªõc `[1, 2048]`)

---

## 8. Hu·∫•n luy·ªán l·∫°i sau khi merge

### Logistic Regression (chu·∫©n h√≥a + pooling)

* D√πng `StandardScaler` chu·∫©n h√≥a:

```python
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

* K·∫øt qu·∫£ confusion matrix:

```
                Predicted
             | Safe | Danger
-------------|------|--------
True Safe    |  23  |   17
True Danger  |   9  |   23
```

![image](https://github.com/user-attachments/assets/47c0c68f-5b37-4f19-a051-b07b2c8a046e)


---

### Random Forest (v·ªõi mean embedding)

* Kh√¥ng c·∫ßn chu·∫©n h√≥a
* K·∫øt qu·∫£:

```
                Predicted
             | Safe | Danger
-------------|------|--------
True Safe    |  31  |   9
True Danger  |   9  |  23
```
![image](https://github.com/user-attachments/assets/b17c6b98-a5c9-4b4e-9368-26548cf7a85a)

---

## 9. Deep Learning v·ªõi TensorFlow/Keras

### üöÄ Ph√°t tri·ªÉn m√¥ h√¨nh MLP (Multi-Layer Perceptron)

Sau khi ƒë·∫°t ƒë∆∞·ª£c k·∫øt qu·∫£ t·ªët v·ªõi Random Forest (83% accuracy), ti·∫øp t·ª•c ph√°t tri·ªÉn v·ªõi m√¥ h√¨nh Deep Learning ƒë·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t.

#### **B∆∞·ªõc 1: X·ª≠ l√Ω d·ªØ li·ªáu cho Deep Learning**

**V·∫•n ƒë·ªÅ v·ªõi d·ªØ li·ªáu ban ƒë·∫ßu:**
- File `audio_embeddings.csv` ch·ª©a d·ªØ li·ªáu d·∫°ng string v·ªõi d·∫•u `...` (ellipsis)
- Ch·ªâ parse ƒë∆∞·ª£c 6 features thay v√¨ 2048 features ƒë·∫ßy ƒë·ªß

**Script: `convertVectors.py`**
```python
# C·∫£i thi·ªán feature extraction t·ª´ CSV
def improve_current_features():
    # Extract nhi·ªÅu features h∆°n t·ª´ d·ªØ li·ªáu CSV
    # T√≠nh to√°n 10 statistical features t·ª´ t·∫•t c·∫£ values c√≥ th·ªÉ parse ƒë∆∞·ª£c
    improved_features = [
        np.mean(all_features), np.std(all_features), 
        np.min(all_features), np.max(all_features),
        np.median(all_features), np.percentile(all_features, 25),
        np.percentile(all_features, 75), len(all_features),
        np.sum(all_features > 0), np.sum(all_features == 0)
    ]
```

**Output:** 
- `X_features_improved.npy`: Shape (360, 10) - 10 statistical features
- `y_labels_improved.npy`: Shape (360,) - Labels

#### **B∆∞·ªõc 2: Ki·∫øn tr√∫c m√¥ h√¨nh MLP**

**Script: `MLP_Keras.py`**
```python
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(10,)),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification
])
```

**C·∫•u h√¨nh training:**
- Optimizer: Adam (learning_rate=0.001)
- Loss: binary_crossentropy
- Metrics: accuracy
- Epochs: 50, Batch size: 32
- Validation split: 20%

#### **B∆∞·ªõc 3: K·∫øt qu·∫£**

| M√¥ h√¨nh | Features | Accuracy | C·∫£i thi·ªán |
|---------|----------|----------|-----------|
| Random Forest | 6 features | 55% | Baseline |
| Random Forest | Mean pooling (2048) | 83% | +28% |
| **MLP Keras** | **10 statistical features** | **üéØ 80.56%** | **Comparable** |

**Confusion Matrix - MLP Improved:**
```
                Predicted
             | Safe | Danger
-------------|------|--------
True Safe    |  XX  |   XX
True Danger  |  XX  |   XX
```

### üß™ **Testing v·ªõi Audio Files th·ª±c t·∫ø**

#### **Audio Safety Classifier API**

**Script: `audio_classifier_api.py`**
```python
class ImprovedAudioClassifier:
    def __init__(self):
        self.model = tf.keras.models.load_model("audio_classification_model_improved.keras")
        self.scaler = joblib.load("scaler_improved.pkl")
    
    def predict(self, audio_path):
        # Extract features t·ª´ audio file
        features = extract_audio_safety_features(audio_path)
        # Scale v√† predict
        probability = self.model.predict(features_scaled)[0][0]
        return {
            'label': 'Danger' if probability > 0.5 else 'Safe',
            'probability': probability,
            'confidence': abs(probability - 0.5) * 2
        }
```

#### **Test Results v·ªõi Audio Files**

**V√≠ d·ª• test case:**
```python
# Test v·ªõi file chu√¥ng ƒëi·ªán tho·∫°i
phone_ring = "resources/R9_ZSCveAHg_7s.mp3"
result = classifier.predict(phone_ring)
# Output: {'label': 'Safe', 'probability': 0.2, 'confidence': 0.6}
```

### üîß **T√≠ch h·ª£p v√†o Kafka Streaming**

#### **Script: `main.py` (Spark Streaming)**

**Th√™m Audio Safety Detection:**
```python
@pandas_udf(safety_schema)
def detect_audio_safety_pandas(processed_16khz: pd.Series) -> pd.Series:
    model, scaler = load_audio_safety_model()
    
    def detect_safety(waveform_data):
        features = extract_audio_safety_features(waveform_data)
        probability = model.predict(features_scaled)[0][0]
        return [
            {"kind": "safe", "likelyhood": 1.0 - probability},
            {"kind": "danger", "likelyhood": probability}
        ]
    return processed_16khz.apply(detect_safety)
```

**Kafka Topics:**
- Input: `anomaly_candidates` (audio chunks)
- Output: `analyzed_anomally` (k·∫øt qu·∫£ anomaly + safety)

### üìä **So s√°nh c√°c ph∆∞∆°ng ph√°p**

| Approach | Features | Accuracy | Pros | Cons |
|----------|----------|----------|------|------|
| **Logistic Regression** | 6 basic | 55% | ƒê∆°n gi·∫£n, nhanh | Kh√¥ng h·ªçc ƒë∆∞·ª£c pattern |
| **Random Forest** | Mean pooling | 83% | Robust, interpretable | Kh√¥ng deep learning |
| **MLP Keras** | 10 statistical | 80.56% | Deep learning, flexible | C·∫ßn nhi·ªÅu data h∆°n |
| **Audio Safety API** | Real-time | Real-time | Production ready | Ph·ª• thu·ªôc v√†o librosa |

### üéØ **K·∫øt lu·∫≠n Deep Learning Phase**

**‚úÖ Th√†nh c√¥ng:**
- X√¢y d·ª±ng ƒë∆∞·ª£c pipeline Deep Learning ho√†n ch·ªânh
- Model MLP ƒë·∫°t accuracy t∆∞∆°ng ƒë∆∞∆°ng Random Forest (80.56%)
- T√≠ch h·ª£p th√†nh c√¥ng v√†o Kafka streaming system
- T·∫°o ƒë∆∞·ª£c API c√≥ th·ªÉ test v·ªõi audio files th·ª±c t·∫ø

**üîÑ B√†i h·ªçc:**
- **Feature Engineering quan tr·ªçng h∆°n model complexity:** Vi·ªác c·∫£i thi·ªán t·ª´ 6 ‚Üí 10 statistical features c√≥ impact l·ªõn
- **Data preprocessing critical:** Parse ƒë√∫ng d·ªØ li·ªáu t·ª´ CSV l√† y·∫øu t·ªë quy·∫øt ƒë·ªãnh
- **Real-world testing:** Model c·∫ßn test v·ªõi audio th·ª±c t·∫ø ƒë·ªÉ validate performance

**üìà H∆∞·ªõng ph√°t tri·ªÉn ti·∫øp theo:**
- S·ª≠ d·ª•ng full 2048 embedding features thay v√¨ statistical summary
- Th·ª≠ c√°c ki·∫øn tr√∫c ph·ª©c t·∫°p h∆°n (CNN, RNN)
- Augment data ƒë·ªÉ tƒÉng size dataset
- Fine-tune pretrained audio models (YAMNet, VGGish)


## 10. K·∫øt lu·∫≠n t·ªïng quan

| M√¥ h√¨nh            | Features | Accuracy | Nh·∫≠n bi·∫øt Danger | Note |
| ------------------ | -------- | -------- | ---------------- | ---- |
| Logistic (raw)     | 6 basic  | 55%      | Kh√¥ng            | Baseline |
| RF (raw)           | 6 basic  | 55%      | Kh√¥ng            | Baseline |
| Logistic + pooling | 2048 pooled | ‚úÖ \~73%  | C√≥               | Mean pooling |
| RF + pooling       | 2048 pooled | ‚úÖ \~83%  | C√≥               | Best traditional ML |
| **MLP Keras**      | **10 statistical** | **‚úÖ 80.56%** | **C√≥** | **Deep Learning** |

### üëâ B√†i h·ªçc ch√≠nh:

* **Feature Engineering > Model Complexity:** C·∫£i thi·ªán features c√≥ impact l·ªõn h∆°n model ph·ª©c t·∫°p
* **Data Preprocessing Critical:** Parse ƒë√∫ng d·ªØ li·ªáu l√† y·∫øu t·ªë quy·∫øt ƒë·ªãnh success
* **Deep Learning Viable:** MLP cho k·∫øt qu·∫£ comparable v·ªõi RF, c√≥ potential scale t·ªët h∆°n
* **Production Ready:** ƒê√£ t√≠ch h·ª£p th√†nh c√¥ng v√†o Kafka streaming system

### üöÄ **Tech Stack ƒë√£ s·ª≠ d·ª•ng:**

- **Audio Processing:** PANNs (Cnn14), librosa
- **Traditional ML:** Random Forest, Logistic Regression  
- **Deep Learning:** TensorFlow/Keras MLP
- **Feature Engineering:** Statistical aggregation, mean pooling
- **Production:** Spark Streaming, Kafka, pandas UDF
- **Testing:** Real audio files, API testing



